{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T20:26:59.016749Z",
     "start_time": "2025-03-11T20:26:57.171866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# version in online jupyter notebook: 0.26.1\n",
    "#!pip install openai==0.26.1\n",
    "\n",
    "!pip list"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- --------------\n",
      "accelerate                0.26.0\n",
      "aiohappyeyeballs          2.5.0\n",
      "aiohttp                   3.11.13\n",
      "aiosignal                 1.3.2\n",
      "annotated-types           0.7.0\n",
      "anyio                     4.8.0\n",
      "argon2-cffi               23.1.0\n",
      "argon2-cffi-bindings      21.2.0\n",
      "arrow                     1.3.0\n",
      "asttokens                 3.0.0\n",
      "async-lru                 2.0.4\n",
      "attrs                     25.1.0\n",
      "babel                     2.17.0\n",
      "beautifulsoup4            4.13.3\n",
      "bleach                    6.2.0\n",
      "certifi                   2025.1.31\n",
      "cffi                      1.17.1\n",
      "charset-normalizer        3.4.1\n",
      "colorama                  0.4.6\n",
      "comm                      0.2.2\n",
      "contourpy                 1.3.1\n",
      "cycler                    0.12.1\n",
      "datasets                  3.2.0\n",
      "debugpy                   1.8.13\n",
      "decorator                 5.2.1\n",
      "defusedxml                0.7.1\n",
      "dill                      0.3.8\n",
      "distro                    1.9.0\n",
      "executing                 2.2.0\n",
      "fastjsonschema            2.21.1\n",
      "filelock                  3.17.0\n",
      "fonttools                 4.56.0\n",
      "fqdn                      1.5.1\n",
      "frozenlist                1.5.0\n",
      "fsspec                    2024.9.0\n",
      "h11                       0.14.0\n",
      "httpcore                  1.0.7\n",
      "httpx                     0.28.1\n",
      "huggingface-hub           0.28.1\n",
      "idna                      3.10\n",
      "ipykernel                 6.29.5\n",
      "ipython                   9.0.1\n",
      "ipython_pygments_lexers   1.1.1\n",
      "ipywidgets                8.1.5\n",
      "isoduration               20.11.0\n",
      "jedi                      0.19.2\n",
      "Jinja2                    3.1.5\n",
      "jiter                     0.9.0\n",
      "joblib                    1.4.2\n",
      "json5                     0.10.0\n",
      "jsonpointer               3.0.0\n",
      "jsonschema                4.23.0\n",
      "jsonschema-specifications 2024.10.1\n",
      "jupyter                   1.1.1\n",
      "jupyter_client            8.6.3\n",
      "jupyter-console           6.6.3\n",
      "jupyter_core              5.7.2\n",
      "jupyter-events            0.12.0\n",
      "jupyter-lsp               2.2.5\n",
      "jupyter_server            2.15.0\n",
      "jupyter_server_terminals  0.5.3\n",
      "jupyterlab                4.3.5\n",
      "jupyterlab_pygments       0.3.0\n",
      "jupyterlab_server         2.27.3\n",
      "jupyterlab_widgets        3.0.13\n",
      "kiwisolver                1.4.8\n",
      "MarkupSafe                3.0.2\n",
      "matplotlib                3.10.1\n",
      "matplotlib-inline         0.1.7\n",
      "mistune                   3.1.2\n",
      "mpmath                    1.3.0\n",
      "multidict                 6.1.0\n",
      "multiprocess              0.70.16\n",
      "nbclient                  0.10.2\n",
      "nbconvert                 7.16.6\n",
      "nbformat                  5.10.4\n",
      "nest-asyncio              1.6.0\n",
      "networkx                  3.4.2\n",
      "notebook                  7.3.2\n",
      "notebook_shim             0.2.4\n",
      "numpy                     2.2.3\n",
      "openai                    0.27.0\n",
      "overrides                 7.7.0\n",
      "packaging                 24.2\n",
      "pandas                    2.2.3\n",
      "pandocfilters             1.5.1\n",
      "parso                     0.8.4\n",
      "peft                      0.14.0\n",
      "pillow                    11.1.0\n",
      "pip                       23.2.1\n",
      "platformdirs              4.3.6\n",
      "prometheus_client         0.21.1\n",
      "prompt_toolkit            3.0.50\n",
      "propcache                 0.3.0\n",
      "psutil                    7.0.0\n",
      "pure_eval                 0.2.3\n",
      "pyarrow                   19.0.1\n",
      "pycparser                 2.22\n",
      "pydantic                  2.10.6\n",
      "pydantic_core             2.27.2\n",
      "Pygments                  2.19.1\n",
      "pyparsing                 3.2.1\n",
      "python-dateutil           2.9.0.post0\n",
      "python-json-logger        3.2.1\n",
      "pytz                      2025.1\n",
      "pywin32                   308\n",
      "pywinpty                  2.0.15\n",
      "PyYAML                    6.0.2\n",
      "pyzmq                     26.2.1\n",
      "referencing               0.36.2\n",
      "regex                     2024.11.6\n",
      "requests                  2.32.3\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rpds-py                   0.23.1\n",
      "safetensors               0.5.3\n",
      "scikit-learn              1.6.1\n",
      "scipy                     1.15.2\n",
      "Send2Trash                1.8.3\n",
      "setuptools                75.8.2\n",
      "six                       1.17.0\n",
      "sniffio                   1.3.1\n",
      "soupsieve                 2.6\n",
      "stack-data                0.6.3\n",
      "sympy                     1.13.1\n",
      "terminado                 0.18.1\n",
      "threadpoolctl             3.5.0\n",
      "tinycss2                  1.4.0\n",
      "tokenizers                0.21.0\n",
      "torch                     2.6.0\n",
      "tornado                   6.4.2\n",
      "tqdm                      4.67.1\n",
      "traitlets                 5.14.3\n",
      "transformers              4.49.0\n",
      "types-python-dateutil     2.9.0.20241206\n",
      "typing_extensions         4.12.2\n",
      "tzdata                    2025.1\n",
      "uri-template              1.3.0\n",
      "urllib3                   2.3.0\n",
      "wcwidth                   0.2.13\n",
      "webcolors                 24.11.1\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.8.0\n",
      "widgetsnbextension        4.0.13\n",
      "xxhash                    3.5.0\n",
      "yarl                      1.18.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T13:29:03.692244Z",
     "start_time": "2025-03-12T13:29:03.679008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "if 'A306709' in os.environ['USERNAME']:\n",
    "    print(\"Running on Christophs computer: update proxy settings.\")\n",
    "    os.environ[\"http_proxy\"] = \"http://sia-lb.telekom.de:8080\"\n",
    "    os.environ[\"https_proxy\"] = \"http://sia-lb.telekom.de:8080\"\n",
    "else:\n",
    "    print(\"Running on any computer but not Christophs: don't update any proxy settings.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Christophs computer: update proxy settings.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "id": "JFJaQyi2-EGC",
    "ExecuteTime": {
     "end_time": "2025-03-11T20:26:59.086986Z",
     "start_time": "2025-03-11T20:26:59.082957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import openai\n",
    "\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "#print(openai.version)\n",
    "#print(openai.__version__)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T20:26:59.127583Z",
     "start_time": "2025-03-11T20:26:59.123707Z"
    }
   },
   "source": [
    "openai.api_key =  os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_base = \"https://openai.vocareum.com/v1\" # Remove this if using personal key\n",
    "#print(openai.api_key)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T20:26:59.148116Z",
     "start_time": "2025-03-11T20:26:59.143780Z"
    }
   },
   "source": [
    "# Decoding parameters\n",
    "TEMPERATURE = 0.0\n",
    "MAX_TOKENS = 3950  # Increased to simulate LLM with smaller attention window\n",
    "TOP_P = 1.0"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GGXSFlArmKt7",
    "ExecuteTime": {
     "end_time": "2025-03-11T20:26:59.159665Z",
     "start_time": "2025-03-11T20:26:59.156001Z"
    }
   },
   "source": [
    "SYSTEM_PROMPT = \"\"\"You expert at games of chance.\n",
    "End every response with double exclamation points!!\"\"\"\n",
    "\n",
    "USER_NAME = \"User\"\n",
    "AI_NAME = \"AI Assistant\"\n",
    "NEW_INTERACTION_DELIMITER = \"\\n\\n\""
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ic4juggvKEB8"
   },
   "source": [
    "# Creating a chat bot with memory\n",
    "Using the basic `openai.Completion` API to understand where the memory \"lives\" in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dVHDhMmZmLHF",
    "ExecuteTime": {
     "end_time": "2025-03-11T20:26:59.176622Z",
     "start_time": "2025-03-11T20:26:59.168034Z"
    }
   },
   "source": [
    "def query_openai(prompt):\n",
    "    response = openai.Completion.create(\n",
    "        model=\"gpt-3.5-turbo-instruct\",\n",
    "        prompt=prompt,\n",
    "        temperature=TEMPERATURE,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        top_p=TOP_P,\n",
    "    )\n",
    "    time.sleep(5) # to avoid rate limit errors\n",
    "    if \"error\" in response:\n",
    "        #raise openai.APIError(response[\"error\"], param=None)\n",
    "        raise openai.InvalidRequestError(response[\"error\"], param=None)\n",
    "    else:\n",
    "        return response.choices[0].text.strip().strip(\"\\n\")\n",
    "\n",
    "\n",
    "def get_system_prompt(input_str=SYSTEM_PROMPT):\n",
    "    return [f\"System:{input_str}\"]\n",
    "\n",
    "\n",
    "def get_convo(input_str, convo):\n",
    "    if not convo:\n",
    "        convo = get_system_prompt()\n",
    "    user_input_str = f\"{USER_NAME}: {input_str}\"\n",
    "    response_trigger = f\"{AI_NAME}: \"\n",
    "    convo.extend([user_input_str, response_trigger])\n",
    "    return convo\n",
    "\n",
    "\n",
    "# This is the function we will be fixing\n",
    "def get_response(input_str, convo, use_simple_truncation, verbose):\n",
    "    \"\"\"\n",
    "    Generate a response from an LLM based on user input_str and conversation history.\n",
    "\n",
    "    Parameters:\n",
    "    input_str (str): The user's current input_str or query to the language model.\n",
    "    convo (list of str): A list representing the history of the conversation.\n",
    "    use_simple_truncation (bool): A flag to determine whether to use a simple truncation\n",
    "                                  method for managing conversation length.\n",
    "    verbose (bool): A flag to determine if entire convo history should be printed.\n",
    "\n",
    "    Returns:\n",
    "    str: The generated response from the language model based on the current input_str and\n",
    "         the conversation history.\n",
    "    \"\"\"\n",
    "    convo = get_convo(input_str, convo)\n",
    "\n",
    "    # Try to prompt model and catch if the prompt exceeds the attention window\n",
    "    first_try = True\n",
    "    atten_window_all_used_up = False\n",
    "    while first_try or atten_window_all_used_up:\n",
    "        # Convo list flattened into string to feed to model\n",
    "        flattened_convo = NEW_INTERACTION_DELIMITER.join(convo)\n",
    "        #flattened_convo = \"\" # TODO\n",
    "        #cut_front = False\n",
    "        #for current_str in convo:\n",
    "        #    flattened_convo += \", \" + current_str\n",
    "        #    cut_front = True\n",
    "        #if cut_front:\n",
    "        #    flattened_convo = flattened_convo[2:]\n",
    "\n",
    "        try:\n",
    "            first_try = False\n",
    "            response = query_openai(flattened_convo)\n",
    "            atten_window_all_used_up = False\n",
    "\n",
    "        except openai.InvalidRequestError as e:\n",
    "        #except openai.APIError as e:\n",
    "            atten_window_all_used_up = True\n",
    "            if verbose:\n",
    "                print(\"** ATTEN_WINDOW ALL USED UP **\")\n",
    "                print(f\"OpenAI Error: {repr(e)}\\n\")\n",
    "\n",
    "            if not convo:\n",
    "                return [\n",
    "                    \"Our Error: System prompt is using up too many tokens of the attention window\"\n",
    "                ]\n",
    "\n",
    "            # We can recover from over-allocation of atten_window by removing \n",
    "            # components from history.\n",
    "            if use_simple_truncation:\n",
    "                # Just remove oldest element in convo\n",
    "                if len(convo) > 0:\n",
    "                    convo = convo[1:]  # TODO\n",
    "\n",
    "            else:\n",
    "                # Remove the oldest User or AI convo turn, while retaining \n",
    "                # system prompt\n",
    "                if len(convo) > 1:\n",
    "                    convo = convo[:1] + convo[2:]  # TODO\n",
    "\n",
    "    # Add the LLM response to the response_trigger\n",
    "    convo[-1] += response\n",
    "    if verbose:\n",
    "        print(NEW_INTERACTION_DELIMITER.join(convo))\n",
    "    else:\n",
    "        print(f\"{USER_NAME}: {input_str}\")\n",
    "        print(f\"{AI_NAME}: {response}\")\n",
    "\n",
    "    return convo\n",
    "\n",
    "\n",
    "def chat(user_query, convo=[], use_simple_truncation=False, verbose=False):\n",
    "    convo = get_response(user_query, convo, use_simple_truncation, verbose)\n",
    "    return convo"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fC6CGoDKK5l9"
   },
   "source": [
    "## Testing our Chat bot"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7MFIxTMRmpL0",
    "ExecuteTime": {
     "end_time": "2025-03-11T20:26:59.189674Z",
     "start_time": "2025-03-11T20:26:59.185658Z"
    }
   },
   "source": [
    "user_inputs = [\n",
    "    \"What cards game has the best odds of winning?\",\n",
    "    \"What are the odds of winning it?\",\n",
    "    \"What is the best hand to be dealt?\",\n",
    "    \"What is the next most likely game to win?\",\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0p61acSK-bW"
   },
   "source": [
    "### Simple convo truncation method\n",
    "Model remembers prior convo but **forgets to** always ends in exclamation points!!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Udi8FpJW8Hf",
    "outputId": "03369e5f-527a-4f7f-fb91-1082ae7d4ed2",
    "ExecuteTime": {
     "end_time": "2025-03-11T20:27:45.220056Z",
     "start_time": "2025-03-11T20:26:59.198530Z"
    }
   },
   "source": [
    "convo = []\n",
    "verbose = False\n",
    "simple_truncation = True\n",
    "for i, input in enumerate(user_inputs):\n",
    "    print(f\"**** Convo turn {i} ****\")\n",
    "    convo = chat(\n",
    "        input, convo=convo, use_simple_truncation=simple_truncation, verbose=verbose\n",
    "    )\n",
    "    print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Convo turn 0 ****\n",
      "User: What cards game has the best odds of winning?\n",
      "AI Assistant: The game of blackjack has the best odds of winning, with a house edge of only 1%!\n",
      "\n",
      "**** Convo turn 1 ****\n",
      "User: What are the odds of winning it?\n",
      "AI Assistant: The odds of winning at blackjack depend on various factors, such as the number of decks in play and the specific rules of the game. However, with proper strategy and a bit of luck, you have a good chance of coming out on top!!\n",
      "\n",
      "**** Convo turn 2 ****\n",
      "User: What is the best hand to be dealt?\n",
      "AI Assistant: The best hand to be dealt in blackjack is a natural blackjack, which is an ace and a 10-value card. This hand pays out at 3:2 and gives you an immediate advantage over the dealer!!\n",
      "\n",
      "**** Convo turn 3 ****\n",
      "User: What is the next most likely game to win?\n",
      "AI Assistant: The next most likely game to win would depend on the specific casino and its games. However, some popular games with good odds of winning include baccarat, craps, and video poker. It's always a good idea to research the odds and strategies for different games before playing.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqcax0zmLs9X"
   },
   "source": [
    "#### What is happening?\n",
    "Peaking under hood to see the full conversation as it grows\n",
    "\n",
    "NOTE: In **convo turn 3** we remove the system prompt to avoid exceeding the LLM attention window\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58SqyIARWT8c",
    "outputId": "984a59ef-495e-457a-e54f-ddb3e3b88352",
    "ExecuteTime": {
     "end_time": "2025-03-11T20:28:29.789153Z",
     "start_time": "2025-03-11T20:27:45.227348Z"
    }
   },
   "source": [
    "convo = []\n",
    "verbose = True\n",
    "simple_truncation = True\n",
    "for i, input in enumerate(user_inputs):\n",
    "    print(f\"**** Convo turn {i} ****\")\n",
    "    convo = chat(\n",
    "        input, convo=convo, use_simple_truncation=simple_truncation, verbose=verbose\n",
    "    )\n",
    "    print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Convo turn 0 ****\n",
      "System:You expert at games of chance.\n",
      "End every response with double exclamation points!!\n",
      "\n",
      "User: What cards game has the best odds of winning?\n",
      "\n",
      "AI Assistant: The game of blackjack has the best odds of winning, with a house edge of only 1%!\n",
      "\n",
      "**** Convo turn 1 ****\n",
      "System:You expert at games of chance.\n",
      "End every response with double exclamation points!!\n",
      "\n",
      "User: What cards game has the best odds of winning?\n",
      "\n",
      "AI Assistant: The game of blackjack has the best odds of winning, with a house edge of only 1%!\n",
      "\n",
      "User: What are the odds of winning it?\n",
      "\n",
      "AI Assistant: The odds of winning at blackjack depend on various factors, such as the number of decks in play and the specific rules of the game. However, with proper strategy and a bit of luck, you have a good chance of coming out on top!!\n",
      "\n",
      "**** Convo turn 2 ****\n",
      "System:You expert at games of chance.\n",
      "End every response with double exclamation points!!\n",
      "\n",
      "User: What cards game has the best odds of winning?\n",
      "\n",
      "AI Assistant: The game of blackjack has the best odds of winning, with a house edge of only 1%!\n",
      "\n",
      "User: What are the odds of winning it?\n",
      "\n",
      "AI Assistant: The odds of winning at blackjack depend on various factors, such as the number of decks in play and the specific rules of the game. However, with proper strategy and a bit of luck, you have a good chance of coming out on top!!\n",
      "\n",
      "User: What is the best hand to be dealt?\n",
      "\n",
      "AI Assistant: The best hand to be dealt in blackjack is a natural blackjack, which is an ace and a 10-value card. This hand pays out at 3:2 and gives you an immediate advantage over the dealer!!\n",
      "\n",
      "**** Convo turn 3 ****\n",
      "** ATTEN_WINDOW ALL USED UP **\n",
      "OpenAI Error: InvalidRequestError(message=<OpenAIObject at 0x1eee4dd2bc0> JSON: {\n",
      "  \"code\": null,\n",
      "  \"message\": \"This model's maximum context length is 4097 tokens, however you requested 4139 tokens (189 in your prompt; 3950 for the completion). Please reduce your prompt; or completion length.\",\n",
      "  \"param\": null,\n",
      "  \"type\": \"invalid_request_error\"\n",
      "}, param=None, code=None, http_status=None, request_id=None)\n",
      "\n",
      "** ATTEN_WINDOW ALL USED UP **\n",
      "OpenAI Error: InvalidRequestError(message=<OpenAIObject at 0x1eefd6efe80> JSON: {\n",
      "  \"code\": null,\n",
      "  \"message\": \"This model's maximum context length is 4097 tokens, however you requested 4121 tokens (171 in your prompt; 3950 for the completion). Please reduce your prompt; or completion length.\",\n",
      "  \"param\": null,\n",
      "  \"type\": \"invalid_request_error\"\n",
      "}, param=None, code=None, http_status=None, request_id=None)\n",
      "\n",
      "** ATTEN_WINDOW ALL USED UP **\n",
      "OpenAI Error: InvalidRequestError(message=<OpenAIObject at 0x1eefd6efe80> JSON: {\n",
      "  \"code\": null,\n",
      "  \"message\": \"This model's maximum context length is 4097 tokens, however you requested 4109 tokens (159 in your prompt; 3950 for the completion). Please reduce your prompt; or completion length.\",\n",
      "  \"param\": null,\n",
      "  \"type\": \"invalid_request_error\"\n",
      "}, param=None, code=None, http_status=None, request_id=None)\n",
      "\n",
      "User: What are the odds of winning it?\n",
      "\n",
      "AI Assistant: The odds of winning at blackjack depend on various factors, such as the number of decks in play and the specific rules of the game. However, with proper strategy and a bit of luck, you have a good chance of coming out on top!!\n",
      "\n",
      "User: What is the best hand to be dealt?\n",
      "\n",
      "AI Assistant: The best hand to be dealt in blackjack is a natural blackjack, which is an ace and a 10-value card. This hand pays out at 3:2 and gives you an immediate advantage over the dealer!!\n",
      "\n",
      "User: What is the next most likely game to win?\n",
      "\n",
      "AI Assistant: The next most likely game to win would depend on the specific casino and its games. However, some popular games with good odds of winning include baccarat, craps, and video poker. It's always a good idea to research the odds and strategies for different games before playing.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDY-XBnUNKUL"
   },
   "source": [
    "### Retaining System prompt truncation method\n",
    "Model remembers most of prior convo and **remembers to** always ends in exclamation points!!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YHJnH0YLJKMX",
    "outputId": "5eea21fe-e65c-4628-a43b-b2fe4bbb3093",
    "ExecuteTime": {
     "end_time": "2025-03-11T20:29:14.811484Z",
     "start_time": "2025-03-11T20:28:29.801164Z"
    }
   },
   "source": [
    "convo = []\n",
    "verbose = False\n",
    "for i, input in enumerate(user_inputs):\n",
    "    print(f\"**** Convo turn {i} ****\")\n",
    "    convo = chat(input, convo=convo, verbose=verbose)\n",
    "    print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Convo turn 0 ****\n",
      "User: What cards game has the best odds of winning?\n",
      "AI Assistant: The game of blackjack has the best odds of winning, with a house edge of only 1%!\n",
      "\n",
      "**** Convo turn 1 ****\n",
      "User: What are the odds of winning it?\n",
      "AI Assistant: The odds of winning at blackjack depend on various factors, such as the number of decks in play and the specific rules of the game. However, with proper strategy and a bit of luck, you have a good chance of coming out on top!!\n",
      "\n",
      "**** Convo turn 2 ****\n",
      "User: What is the best hand to be dealt?\n",
      "AI Assistant: The best hand to be dealt in blackjack is a natural blackjack, which is an ace and a 10-value card. This hand pays out at 3:2 and gives you an immediate advantage over the dealer!!\n",
      "\n",
      "**** Convo turn 3 ****\n",
      "User: What is the next most likely game to win?\n",
      "AI Assistant: The next most likely game to win would depend on your personal preferences and skills. Some popular games of chance include poker, roulette, and baccarat. However, with your expertise, you may have a higher chance of winning at any game you choose!!\n",
      "\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBRZFXA6MltU"
   },
   "source": [
    "#### What is happening?\n",
    "Peaking under hood to see full convo as it grows\n",
    "\n",
    "NOTE: In **convo turn 3** we remove the oldest **convo turns**, but retain the system prompt"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qbSxLx9_M4lw",
    "outputId": "7f1eda93-8c09-4cae-8a4a-e47333e49105",
    "ExecuteTime": {
     "end_time": "2025-03-11T20:30:00.038792Z",
     "start_time": "2025-03-11T20:29:14.820613Z"
    }
   },
   "source": [
    "convo = []\n",
    "verbose = True\n",
    "for i, input in enumerate(user_inputs):\n",
    "    print(f\"**** Convo turn {i} ****\")\n",
    "    convo = chat(input, convo=convo, verbose=verbose)\n",
    "    print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Convo turn 0 ****\n",
      "System:You expert at games of chance.\n",
      "End every response with double exclamation points!!\n",
      "\n",
      "User: What cards game has the best odds of winning?\n",
      "\n",
      "AI Assistant: The game of blackjack has the best odds of winning, with a house edge of only 1%!\n",
      "\n",
      "**** Convo turn 1 ****\n",
      "System:You expert at games of chance.\n",
      "End every response with double exclamation points!!\n",
      "\n",
      "User: What cards game has the best odds of winning?\n",
      "\n",
      "AI Assistant: The game of blackjack has the best odds of winning, with a house edge of only 1%!\n",
      "\n",
      "User: What are the odds of winning it?\n",
      "\n",
      "AI Assistant: The odds of winning at blackjack depend on various factors, such as the number of decks in play and the specific rules of the game. However, with proper strategy and a bit of luck, you have a good chance of coming out on top!!\n",
      "\n",
      "**** Convo turn 2 ****\n",
      "System:You expert at games of chance.\n",
      "End every response with double exclamation points!!\n",
      "\n",
      "User: What cards game has the best odds of winning?\n",
      "\n",
      "AI Assistant: The game of blackjack has the best odds of winning, with a house edge of only 1%!\n",
      "\n",
      "User: What are the odds of winning it?\n",
      "\n",
      "AI Assistant: The odds of winning at blackjack depend on various factors, such as the number of decks in play and the specific rules of the game. However, with proper strategy and a bit of luck, you have a good chance of coming out on top!!\n",
      "\n",
      "User: What is the best hand to be dealt?\n",
      "\n",
      "AI Assistant: The best hand to be dealt in blackjack is a natural blackjack, which is an ace and a 10-value card. This hand pays out at 3:2 and gives you an immediate advantage over the dealer!!\n",
      "\n",
      "**** Convo turn 3 ****\n",
      "** ATTEN_WINDOW ALL USED UP **\n",
      "OpenAI Error: InvalidRequestError(message=<OpenAIObject at 0x1eefdc9ae40> JSON: {\n",
      "  \"code\": null,\n",
      "  \"message\": \"This model's maximum context length is 4097 tokens, however you requested 4139 tokens (189 in your prompt; 3950 for the completion). Please reduce your prompt; or completion length.\",\n",
      "  \"param\": null,\n",
      "  \"type\": \"invalid_request_error\"\n",
      "}, param=None, code=None, http_status=None, request_id=None)\n",
      "\n",
      "** ATTEN_WINDOW ALL USED UP **\n",
      "OpenAI Error: InvalidRequestError(message=<OpenAIObject at 0x1eefdc9b7f0> JSON: {\n",
      "  \"code\": null,\n",
      "  \"message\": \"This model's maximum context length is 4097 tokens, however you requested 4127 tokens (177 in your prompt; 3950 for the completion). Please reduce your prompt; or completion length.\",\n",
      "  \"param\": null,\n",
      "  \"type\": \"invalid_request_error\"\n",
      "}, param=None, code=None, http_status=None, request_id=None)\n",
      "\n",
      "** ATTEN_WINDOW ALL USED UP **\n",
      "OpenAI Error: InvalidRequestError(message=<OpenAIObject at 0x1eefdcb3340> JSON: {\n",
      "  \"code\": null,\n",
      "  \"message\": \"This model's maximum context length is 4097 tokens, however you requested 4103 tokens (153 in your prompt; 3950 for the completion). Please reduce your prompt; or completion length.\",\n",
      "  \"param\": null,\n",
      "  \"type\": \"invalid_request_error\"\n",
      "}, param=None, code=None, http_status=None, request_id=None)\n",
      "\n",
      "System:You expert at games of chance.\n",
      "End every response with double exclamation points!!\n",
      "\n",
      "AI Assistant: The odds of winning at blackjack depend on various factors, such as the number of decks in play and the specific rules of the game. However, with proper strategy and a bit of luck, you have a good chance of coming out on top!!\n",
      "\n",
      "User: What is the best hand to be dealt?\n",
      "\n",
      "AI Assistant: The best hand to be dealt in blackjack is a natural blackjack, which is an ace and a 10-value card. This hand pays out at 3:2 and gives you an immediate advantage over the dealer!!\n",
      "\n",
      "User: What is the next most likely game to win?\n",
      "\n",
      "AI Assistant: The next most likely game to win would depend on your personal preferences and skills. Some popular games of chance include poker, roulette, and baccarat. However, with your expertise, you may have a higher chance of winning at any game you choose!!\n",
      "\n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOb/Rz98rOFMFcM/oGGqMP4",
   "include_colab_link": true,
   "mount_file_id": "15ObT0WPB-oL1W-p7iT5JP2oHwSKDmWBb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
