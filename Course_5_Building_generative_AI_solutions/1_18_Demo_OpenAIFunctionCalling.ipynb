{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll demonstrate how to use OpenAI functioncalling.  We'll use the GPT-3.5 model to identify and call a function in the context of a conversation. We will use a simple function that returns a string as a response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:46:07.459859Z",
     "start_time": "2025-03-28T16:46:07.456553Z"
    }
   },
   "source": [
    "# Importing the necessary library for OpenAI API\n",
    "import os\n",
    "import openai\n",
    "openai.api_base = \"https://openai.vocareum.com/v1\"\n",
    "# Importing the necessary library for JSON used in OpenAI API calls\n",
    "import json \n",
    "\n",
    "# Define your OpenAI API key \n",
    "api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "openai.api_key = api_key"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Define the Function\n",
    "\n",
    "First, let's define a simple Python function that takes a string as an argument and returns a string as a response."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:46:12.505551Z",
     "start_time": "2025-03-28T16:46:12.501469Z"
    }
   },
   "source": [
    "def simple_function(input_string):\n",
    "    return f\"Function called with argument: {input_string}\""
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Define the Tools\n",
    "\n",
    "Next, we define the `tools` list. This list contains the functions that the assistant can use. Each function is described by its name, description, and parameters."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:46:29.500187Z",
     "start_time": "2025-03-28T16:46:29.495552Z"
    }
   },
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"simple_function\",\n",
    "            \"description\": \"A simple function that returns a string\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"input_string\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"A string to pass to the function\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"input_string\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Define the Initial Conversation Messages\n",
    "\n",
    "We define the initial conversation messages. The first message is from the system, describing the role of the assistant. The second message is from the user, requesting the function call. Feel free to change the argument!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:47:03.706630Z",
     "start_time": "2025-03-28T16:47:03.702243Z"
    }
   },
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an assistant that can call a simple function.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Call the simple function with the argument 'Hello there, World!'.\"}\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Generate a Response from the Model\n",
    "\n",
    "We call `openai.ChatCompletion.create()` (for openai < 1.0) or `openai.chat.completions.create()` (for openai > 1.0) to generate a response from the GPT-3.5 model. The model, messages, and tools are passed as arguments. The `tool_choice` is set to \"auto\", allowing the model to choose which tool (function) to use."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:47:23.461558Z",
     "start_time": "2025-03-28T16:47:17.463503Z"
    }
   },
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:47:52.385443Z",
     "start_time": "2025-03-28T16:47:52.380815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Christoph:\n",
    "print(response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"tool_calls\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"annotations\": [],\n",
      "        \"content\": null,\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"function\": {\n",
      "              \"arguments\": \"{\\\"input_string\\\":\\\"Hello there, World!\\\"}\",\n",
      "              \"name\": \"simple_function\"\n",
      "            },\n",
      "            \"id\": \"call_yheqGtkayvzUW1ZWdpd2hFPH\",\n",
      "            \"type\": \"function\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1743180438,\n",
      "  \"id\": \"chatcmpl-BG79SnDdLk6iKj7C8h9yksE7XTKdF\",\n",
      "  \"model\": \"gpt-3.5-turbo-0125\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": \"default\",\n",
      "  \"system_fingerprint\": null,\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 20,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 82,\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 102\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Extract the Tool Calls and Call the Function\n",
    "\n",
    "We extract any tool calls from the response. \n",
    "\n",
    "- If there are any tool calls, we map the tool names to their corresponding Python functions. \n",
    "- For each tool call in the response, we extract the function name and call the corresponding Python function with the arguments provided by the model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:50:05.477732Z",
     "start_time": "2025-03-28T16:50:05.471979Z"
    }
   },
   "source": [
    "tool_calls = response.choices[0].message.tool_calls\n",
    "\n",
    "if tool_calls:\n",
    "    available_functions = {\n",
    "        \"simple_function\": simple_function,\n",
    "    }\n",
    "\n",
    "    for tool_call in tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "        if function_name == 'simple_function':\n",
    "            function_response = function_to_call(\n",
    "                input_string=function_args.get(\"input_string\"),\n",
    "            )\n",
    "\n",
    "        messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": function_response,\n",
    "        })"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Print the Conversation\n",
    "\n",
    "Finally, we print the conversation messages to see the function call and response in the context of the conversation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T16:50:08.884211Z",
     "start_time": "2025-03-28T16:50:08.880126Z"
    }
   },
   "source": [
    "for message in messages:\n",
    "    print(f\"{message['role']}: {message['content']}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system: You are an assistant that can call a simple function.\n",
      "user: Call the simple function with the argument 'Hello there, World!'.\n",
      "assistant: Function called with argument: Hello there, World!\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
